{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fantastic-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://amunategui.github.io/unconventional-convolutional-networks/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "metric-playlist",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (2.3.0)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (0.36.2)\n",
      "Requirement already satisfied: tensorboard<3,>=2.3.0 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (1.18.5)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (3.14.0)\n",
      "Requirement already satisfied: gast==0.3.3 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (0.3.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: absl-py>=0.7.0 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (0.11.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.8 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (2.3.0)\n",
      "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (2.10.0)\n",
      "Requirement already satisfied: wrapt>=1.11.1 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (1.12.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (1.35.0)\n",
      "Requirement already satisfied: astunparse==1.6.3 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: scipy==1.4.1 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorflow) (1.4.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (3.3.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (0.4.2)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (2.25.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.6.0)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.3 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.27.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from tensorboard<3,>=2.3.0->tensorflow) (52.0.0.post20210125)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.2.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (4.7)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (1.26.3)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow) (2.10)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\admin\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install xgboost\n",
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "entitled-orbit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing needed packages\n",
    "from numpy import loadtxt\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifty-business",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "three-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as pdr\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peripheral-thunder",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "center-beads",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL\n",
      "500\n",
      "AXP\n",
      "500\n",
      "BA\n",
      "500\n",
      "CAT\n",
      "500\n",
      "x_train_mod shape: (1432, 20, 20, 1)\n",
      "x_valid shape: (544, 20, 20, 1)\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 16, 16, 64)        1664      \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 13, 13, 10)        1290      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 6, 6, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 360)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               46208     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 74,178\n",
      "Trainable params: 74,178\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_3 (Conv2D)            (None, 18, 18, 64)        640       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 18, 18, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 9, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 32)          8224      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 8, 8, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                32832     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2)                 130       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 41,826\n",
      "Trainable params: 41,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "2/2 [==============================] - 1s 275ms/step - loss: 0.7105 - accuracy: 0.4797 - val_loss: 0.1594 - val_accuracy: 1.0000\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 0s 170ms/step - loss: 0.1515 - accuracy: 1.0000 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 0s 180ms/step - loss: 0.0484 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 0s 188ms/step - loss: 0.0239 - accuracy: 1.0000 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 0.0155 - accuracy: 1.0000 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 0s 176ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 0s 173ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 0s 172ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 7.5095e-04 - val_accuracy: 1.0000\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 0s 181ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 5.2047e-04 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.5866e-04 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 0s 197ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.5140e-04 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 0s 217ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 1.8700e-04 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 0s 189ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 1.3765e-04 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 0s 167ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.0331e-04 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 0s 179ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 7.6411e-05 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 0s 162ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 5.2920e-05 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 0s 164ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.8079e-05 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 0s 143ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.7982e-05 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 0s 132ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.0445e-05 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 0s 137ms/step - loss: 9.5798e-04 - accuracy: 1.0000 - val_loss: 1.4999e-05 - val_accuracy: 1.0000\n",
      "Outcome balance 0.000000\n",
      "AUC: nan\n",
      "Accuracy on all data: 1.0\n",
      "Accuracy on higher threshold: nan\n",
      "Returns: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\sklearn\\metrics\\_ranking.py:949: UndefinedMetricWarning: No positive samples in y_true, true positive value should be meaningless\n",
      "  warnings.warn(\"No positive samples in y_true, \"\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\numpy\\lib\\function_base.py:393: RuntimeWarning: Mean of empty slice.\n",
      "  avg = a.mean(axis)\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\numpy\\core\\_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def scale_list(l, to_min, to_max):\n",
    "    def scale_number(unscaled, to_min, to_max, from_min, from_max):\n",
    "        return (to_max-to_min)*(unscaled-from_min)/(from_max-from_min)+to_min\n",
    "\n",
    "    if len(set(l)) == 1:\n",
    "        return [np.floor((to_max + to_min)/2)] * len(l)\n",
    "    else:\n",
    "        return [scale_number(i, to_min, to_max, min(l), max(l)) for i in l]\n",
    " \n",
    "\n",
    "#STOCKS = ['AAPL']\n",
    "STOCKS = ['AAPL','AXP','BA','CAT']\n",
    "TIME_RANGE = 20\n",
    "PRICE_RANGE = 20\n",
    "VALIDTAION_CUTOFF_DATE = datetime.date(2017, 7, 1)\n",
    "\n",
    "# split image horizontally into two sections - top and bottom sections\n",
    "half_scale_size = int(PRICE_RANGE/2)\n",
    " \n",
    "live_symbols = []\n",
    "x_live = None\n",
    "x_train = None\n",
    "x_valid = None\n",
    "y_train = []\n",
    "y_valid = []\n",
    "\n",
    "# xgboost lists\n",
    "live_data_xgboost = []\n",
    "validation_data_xgboost = []\n",
    "train_data_xgboost = []\n",
    "\n",
    "for stock in STOCKS:\n",
    "    print(stock)\n",
    "\n",
    "    # build image data for this stock\n",
    "    # stock_data = pdr.get_data_google(stock)\n",
    "\n",
    "    # download dataframe\n",
    "    stock_data = pdr.get_data_yahoo(stock, start=\"2016-01-01\", end=\"2018-01-17\")\n",
    "\n",
    "    stock_data['Symbol'] = stock\n",
    "    stock_data['Date'] = stock_data.index\n",
    "    stock_data['Date'] = pd.to_datetime(stock_data['Date'], infer_datetime_format=True)\n",
    "    stock_data['Date'] = stock_data['Date'].dt.date\n",
    "    stock_data = stock_data.reset_index(drop=True)\n",
    " \n",
    "   # add Moving Averages to all lists and back fill resulting first NAs to last known value\n",
    "    noise_ma_smoother = 3\n",
    "    stock_closes = stock_data['Close'].rolling(window=noise_ma_smoother).mean()\n",
    "    #stock_closes = pd.rolling_mean(stock_data['Close'], window = noise_ma_smoother) \n",
    "    stock_closes = stock_closes.fillna(method='bfill')  \n",
    "    stock_closes =  list(stock_closes.values)\n",
    "    stock_opens = stock_data['Open'].rolling(window=noise_ma_smoother).mean()\n",
    "    #stock_opens = pd.rolling_mean(stock_data['Open'], window = noise_ma_smoother)\n",
    "    stock_opens = stock_opens.fillna(method='bfill')  \n",
    "    stock_opens =  list(stock_opens.values)\n",
    "    \n",
    "    stock_dates = stock_data['Date'].values \n",
    "  \n",
    "    close_minus_open = list(np.array(stock_closes) - np.array(stock_opens))\n",
    "    \n",
    " # lets add a rolling average as an overlay indicator - back fill the missing\n",
    "    # first five values with the first available avg price\n",
    "    longer_ma_smoother = 6\n",
    "    #stock_closes_rolling_avg = pd.rolling_mean(stock_data['Close'], window = longer_ma_smoother)\n",
    "    stock_closes_rolling_avg = stock_data['Close'].rolling(window=noise_ma_smoother).mean()\n",
    "    stock_closes_rolling_avg = stock_closes_rolling_avg.fillna(method='bfill')  \n",
    "    stock_closes_rolling_avg =  list(stock_closes_rolling_avg.values)\n",
    "\n",
    "    for cnt in range(4, len(stock_closes)):\n",
    "        if (cnt % 500 == 0): print(cnt)\n",
    "\n",
    "        if (cnt >= TIME_RANGE):\n",
    "            # start making images\n",
    "            graph_open = list(np.round(scale_list(stock_opens[cnt-TIME_RANGE:cnt], 0, half_scale_size-1),0))\n",
    "            graph_close_minus_open = list(np.round(scale_list(close_minus_open[cnt-TIME_RANGE:cnt], 0, half_scale_size-1),0))\n",
    "            \n",
    "            # scale both close and close MA toeghertogether\n",
    "            close_data_together = list(np.round(scale_list(list(stock_closes[cnt-TIME_RANGE:cnt]) + \n",
    "                list(stock_closes_rolling_avg[cnt-TIME_RANGE:cnt]), 0, half_scale_size-1),0))\n",
    "            graph_close = close_data_together[0:PRICE_RANGE]\n",
    "            graph_close_ma = close_data_together[PRICE_RANGE:] \n",
    "\n",
    "            outcome = None\n",
    "            if (cnt < len(stock_closes) -1):\n",
    "                outcome = 0\n",
    "                if stock_closes[cnt+1] > stock_closes_rolling_avg[cnt+1]:\n",
    "                    outcome = 1\n",
    "\n",
    "            blank_matrix_close = np.zeros(shape=(half_scale_size, TIME_RANGE))\n",
    "            x_ind = 0\n",
    "            for ma, c in zip(graph_close_ma, graph_close):\n",
    "                blank_matrix_close[int(ma), x_ind] = 1 \n",
    "                blank_matrix_close[int(c), x_ind] = 2  \n",
    "                x_ind += 1\n",
    "\n",
    "            # flip x scale dollars so high number is atop, low number at bottom - cosmetic, humans only\n",
    "            blank_matrix_close = blank_matrix_close[::-1]\n",
    "\n",
    "            # store image data into matrix DATA_SIZE*DATA_SIZE\n",
    "            blank_matrix_diff = np.zeros(shape=(half_scale_size, TIME_RANGE))\n",
    "            x_ind = 0\n",
    "            for v in graph_close_minus_open:\n",
    "                blank_matrix_diff[int(v), x_ind] = 3  \n",
    "                x_ind += 1\n",
    "            # flip x scale so high number is atop, low number at bottom - cosmetic, humans only\n",
    "            blank_matrix_diff = blank_matrix_diff[::-1]\n",
    "\n",
    "            blank_matrix = np.vstack([blank_matrix_close, blank_matrix_diff]) \n",
    "\n",
    "            if 1==2:\n",
    "                # graphed on matrix\n",
    "                plt.imshow(blank_matrix)\n",
    "                plt.show()\n",
    "\n",
    "                # straight timeseries \n",
    "                plt.plot(graph_close, color='black')\n",
    "                plt.show()\n",
    "\n",
    "            if (outcome == None):\n",
    "                # live data\n",
    "                if x_live is None:\n",
    "                    x_live =[blank_matrix]\n",
    "                else:\n",
    "                    x_live = np.vstack([x_live, [blank_matrix]])\n",
    "                live_symbols.append(stock)\n",
    "\n",
    "                live_data_xgboost.append(graph_close_ma + graph_close + graph_close_minus_open + [0])\n",
    "\n",
    "            elif (stock_dates[cnt] >= VALIDTAION_CUTOFF_DATE):\n",
    "                # validation data\n",
    "                if x_valid is None:\n",
    "                    x_valid = [blank_matrix]\n",
    "                else:\n",
    "                    x_valid = np.vstack([x_valid, [blank_matrix]])\n",
    "                y_valid.append(outcome)\n",
    "\n",
    "                validation_data_xgboost.append(graph_close_ma + graph_close + graph_close_minus_open + [outcome])\n",
    "\n",
    "            else:\n",
    "                # training data\n",
    "                if x_train is None:\n",
    "                    x_train = [blank_matrix]\n",
    "                else:\n",
    "                    x_train = np.vstack([x_train, [blank_matrix]])\n",
    "                y_train.append(outcome)\n",
    "\n",
    "                train_data_xgboost.append(graph_close_ma + graph_close + graph_close_minus_open + [outcome])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "####################################################################\n",
    "# Run simple keras CNN model\n",
    "####################################################################\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 1000\n",
    "num_classes = 2\n",
    "epochs = 20\n",
    " \n",
    "# input image dimensions\n",
    "img_rows, img_cols = TIME_RANGE, PRICE_RANGE\n",
    "\n",
    "# add fake depth channel \n",
    "x_train_mod = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_valid = x_valid.reshape(x_valid.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (TIME_RANGE, PRICE_RANGE, 1)\n",
    "\n",
    "x_train_mod = x_train_mod.astype('float32')\n",
    "x_valid = x_valid.astype('float32')\n",
    "\n",
    "print('x_train_mod shape:', x_train_mod.shape)\n",
    "print('x_valid shape:', x_valid.shape)\n",
    " \n",
    "y_train_mod = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_valid_mod = keras.utils.to_categorical(y_valid, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (5, 5), input_shape=input_shape, activation='relu'))\n",
    "model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(Conv2D(10, (2, 2), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "######################## testing\n",
    "# https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())  \n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "#################################\n",
    "\n",
    "\n",
    "model.fit(x_train_mod, y_train_mod,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_train_mod, y_train_mod))\n",
    " \n",
    "\n",
    "score = model.evaluate(x_train_mod, y_train_mod, verbose=0)\n",
    "# print('Test loss:', score[0])\n",
    "# print('Test accuracy:', score[1])\n",
    " \n",
    "predictions_cnn = model.predict(x_valid)\n",
    "\n",
    "# run an accuracy or auc test\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    " \n",
    "# balance\n",
    "print('Outcome balance %f' % np.mean(y_train_mod[:,1]))\n",
    "\n",
    "# print('Model accuracy: ', accuracy_score(y_valid_mod[:,1], temp_predictions,'%'))\n",
    "fpr, tpr, thresholds = roc_curve(y_valid_mod[:,1], predictions_cnn[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print('AUC: %f' % roc_auc)\n",
    "from sklearn.metrics import roc_auc_score\n",
    " \n",
    "\n",
    "####################################################################\n",
    "# Play around with thresholds to pick the best predictions\n",
    "####################################################################\n",
    "\n",
    "# pick top of class to find best bets \n",
    "actuals = y_valid_mod[:,1]\n",
    "preds = predictions_cnn[:,1]\n",
    "from sklearn.metrics import accuracy_score\n",
    "print ('Accuracy on all data:', accuracy_score(actuals,[1 if x >= 0.5 else 0 for x in preds]))\n",
    " \n",
    "threshold = 0.75\n",
    "preds = predictions_cnn[:,1][predictions_cnn[:,1] >= threshold]\n",
    "actuals = y_valid_mod[:,1][predictions_cnn[:,1] >= threshold]\n",
    "from sklearn.metrics import accuracy_score\n",
    "print ('Accuracy on higher threshold:', accuracy_score(actuals,[1 if x > 0.5 else 0 for x in preds]))\n",
    "print('Returns:',len(actuals))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "oriental-vinyl",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:22:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[20:22:11] C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/metric/rank_metric.cc:233: Check failed: dat[1] > 0.0f (0 vs. 0) : AUC: the dataset only contains pos or neg samples",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7d79c642ae23>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m model_xgb = xgb.train ( params = param,\n\u001b[0m\u001b[0;32m     27\u001b[0m               \u001b[0mdtrain\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m               \u001b[0mnum_boost_round\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks)\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[0mBooster\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtrained\u001b[0m \u001b[0mbooster\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m     \"\"\"\n\u001b[1;32m--> 227\u001b[1;33m     bst = _train_internal(params, dtrain,\n\u001b[0m\u001b[0;32m    228\u001b[0m                           \u001b[0mnum_boost_round\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_boost_round\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                           \u001b[0mevals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\xgboost\\training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks, evals_result, maximize, verbose_eval, early_stopping_rounds)\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[0mnboost\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[1;31m# check evaluation result.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mafter_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;31m# do checkpoint after evaluation, in case evaluation also updates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\xgboost\\callback.py\u001b[0m in \u001b[0;36mafter_iteration\u001b[1;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[0;32m    421\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'-'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Dataset name should not contain `-`'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevals\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# into datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m             \u001b[1;31m# split up `test-error:0.1234`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36meval_set\u001b[1;34m(self, evals, iteration, feval)\u001b[0m\n\u001b[0;32m   1342\u001b[0m         \u001b[0mevnames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mc_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mevals\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1343\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1344\u001b[1;33m         _check_call(_LIB.XGBoosterEvalOneIter(self.handle,\n\u001b[0m\u001b[0;32m   1345\u001b[0m                                               \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miteration\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1346\u001b[0m                                               \u001b[0mdmats\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevnames\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Tensorflow\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    187\u001b[0m     \"\"\"\n\u001b[0;32m    188\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 189\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [20:22:11] C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/metric/rank_metric.cc:233: Check failed: dat[1] > 0.0f (0 vs. 0) : AUC: the dataset only contains pos or neg samples"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "# XGBoost\n",
    "####################################################################\n",
    "\n",
    "train_xgboost = pd.DataFrame(train_data_xgboost)\n",
    "val_xgboost = pd.DataFrame(validation_data_xgboost)\n",
    "\n",
    "outcome = 8\n",
    "features = [x for x in range(0,8)]\n",
    "\n",
    "import xgboost as xgb\n",
    "dtrain = xgb.DMatrix(data=train_xgboost[features],\n",
    "  label = train_xgboost[[outcome]])\n",
    "dval = xgb.DMatrix(data=val_xgboost[features],\n",
    "  label = val_xgboost[[outcome]])\n",
    "\n",
    "evals = [(dval,'eval'), (dtrain,'train')]\n",
    "\n",
    "param = {'max_depth': 4, \n",
    "       'eta':0.01, 'silent':1,\n",
    "       'eval_metric':'auc', \n",
    "       'subsample': 0.7,\n",
    "       'colsample_bytree': 0.8}\n",
    "        \n",
    "\n",
    "model_xgb = xgb.train ( params = param,\n",
    "              dtrain = dtrain,\n",
    "              num_boost_round = 1000,\n",
    "              verbose_eval=10, \n",
    "              early_stopping_rounds = 100,\n",
    "              evals=evals,\n",
    "              maximize = True)\n",
    "####################################################################\n",
    "#Predict training set:\n",
    "####################################################################\n",
    "\n",
    "predictions_xgb = model_xgb.predict(dval)\n",
    "predictions_class = [1 if x >= 0.5 else 0 for x in predictions_xgb]\n",
    "\n",
    "from sklearn import cross_validation, metrics    \n",
    "print (\"\\nModel Report\")\n",
    "print (\"Accuracy : %.4g\" % metrics.accuracy_score(val_xgboost[outcome], predictions_class))\n",
    "print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(val_xgboost[outcome], predictions_xgb))\n",
    "best_picks_val = val_xgboost[outcome][predictions_xgb > 0.8]\n",
    "\n",
    "threshold = 0.7\n",
    "preds = predictions_xgb[predictions_xgb >= threshold]\n",
    "actuals = val_xgboost[outcome][predictions_xgb >= threshold]\n",
    "from sklearn.metrics import accuracy_score\n",
    "print (accuracy_score(actuals,[1] * len(actuals)))\n",
    " \n",
    "# plot the important features #\n",
    "fig, ax = plt.subplots(figsize=(7,7))\n",
    "xgb.plot_importance(model_xgb,  height=0.8, ax=ax)\n",
    "plt.show()\n",
    "\n",
    "####################################################################\n",
    "# Ensembled\n",
    "####################################################################\n",
    "ensemble = (predictions_xgb + predictions_cnn[:,1]) / 2\n",
    "ensemble_class = [1 if x >= 0.5 else 0 for x in ensemble]\n",
    "print (\"Accuracy : %.4g\" % metrics.accuracy_score(val_xgboost[outcome], ensemble_class))\n",
    "print (\"AUC Score (Train): %f\" % metrics.roc_auc_score(val_xgboost[outcome], ensemble))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-gazette",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Version of Python\n",
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "greenhouse-encoding",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(xgb.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(matplotlib._version_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ahead-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model to file\n",
    "        mlflow.sklearn.save_model(bst, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-success",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
